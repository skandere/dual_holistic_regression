{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Dual Approach to Holistic Regression\n",
    "## March 4th, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Distributions\n",
    "using LinearAlgebra\n",
    "using Gurobi, JuMP\n",
    "using DataFrames\n",
    "using CSV\n",
    "using StatsBase\n",
    "using Plots\n",
    "using ProgressBars\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gurobi_env = Gurobi.Env()\n",
    "\n",
    "function create_gurobi_model(; TimeLimit=-1, LogFile=nothing)\n",
    "    model = Model(optimizer_with_attributes(() -> Gurobi.Optimizer(gurobi_env)));\n",
    "    if TimeLimit >= 0\n",
    "        println(\"Set Gurobi TimeLimit.\")\n",
    "        set_optimizer_attribute(model, \"TimeLimit\", TimeLimit)\n",
    "    end\n",
    "    if LogFile != nothing\n",
    "        println(\"LogFile: $(LogFile).\")\n",
    "        set_optimizer_attribute(model, \"LogFile\", LogFile)\n",
    "    else\n",
    "        set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "    end\n",
    "    set_optimizer_attribute(model, \"NumericFocus\", 3)\n",
    "    return model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## 0. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_list(file_path, l)\n",
    "    if length(l) == 0\n",
    "        return\n",
    "    end\n",
    "    open(file_path, \"a+\") do io\n",
    "        for e in l[1:end-1]\n",
    "            try \n",
    "                e = round(e, digits=3)\n",
    "                catch error end\n",
    "            write(io, \"$(e),\")\n",
    "        end\n",
    "        e = l[end]\n",
    "        try \n",
    "            e = round(e, digits=3)\n",
    "        catch error end\n",
    "        write(io, \"$(e)\\n\")\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "function write_to_file(file_path, str)\n",
    "    open(file_path, \"a+\") do io\n",
    "        write(io, str)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_support(s)\n",
    "    supp = similar(s, Int)\n",
    "    count_supp = 1\n",
    "    \n",
    "    supp_c = similar(s, Int)\n",
    "    count_supp_c = 1\n",
    "    \n",
    "    @inbounds for i in eachindex(s)\n",
    "        supp[count_supp] = i\n",
    "        supp_c[count_supp_c] = i\n",
    "        is_zero = s[i] < 0.5\n",
    "        count_supp += !is_zero\n",
    "        count_supp_c += is_zero\n",
    "    end\n",
    "    return resize!(supp, count_supp-1), resize!(supp_c, count_supp_c-1)\n",
    "end\n",
    "\n",
    "get_support([0, 0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## 1. Generate Synthetic Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_synthetic_data(n, p, k, NR; seed=-1)\n",
    "    \"\"\"\n",
    "        n = num. of samples\n",
    "        p = num. of features\n",
    "        k = num. of non zero coefficients\n",
    "        NR = noise ratio ~ σ_noise = NR * σ_y_true\n",
    "    \"\"\"\n",
    "    if seed >= 0\n",
    "        Random.seed!(seed)\n",
    "    end\n",
    "    \n",
    "    # Generate PD matrix\n",
    "    A = randn(p, p)\n",
    "    A = A'*A\n",
    "    Σ = (A' + A)/2\n",
    "    \n",
    "    # Generate data X\n",
    "    d = MvNormal(Σ)\n",
    "    X = rand(d, n)'I\n",
    "    \n",
    "    # Split data\n",
    "    index_train = 1:floor(Int, 0.5*n)\n",
    "    index_val = floor(Int, 0.5*n)+1:floor(Int, 0.75*n)\n",
    "    index_test = floor(Int, 0.75*n)+1:n\n",
    "    \n",
    "    X_train = X[index_train,:]\n",
    "    X_val = X[index_val,:]\n",
    "    X_test = X[index_test,:]\n",
    "    \n",
    "    # Center\n",
    "    μ_train = [mean(X_train[:, j]) for j=1:p]\n",
    "    for j=1:p\n",
    "         X_train[:,j] = X_train[:,j] .- μ_train[j]\n",
    "         X_val[:,j] = X_val[:,j] .- μ_train[j]\n",
    "         X_test[:,j] = X_test[:,j] .- μ_train[j]\n",
    "    end\n",
    "    \n",
    "    # Scale\n",
    "    σ_train = [norm(X_train[:, j]) for j=1:p]\n",
    "    for j=1:p\n",
    "         X_train[:,j] = X_train[:,j]/σ_train[j]\n",
    "         X_val[:,j] = X_val[:,j] ./ σ_train[j]\n",
    "         X_test[:,j] = X_test[:,j] ./ σ_train[j]\n",
    "    end\n",
    "    \n",
    "    # Generate β\n",
    "    β = zeros(p)\n",
    "    for j=1:k\n",
    "        β[floor(Int, j*p/k)] = 1.0*rand([-1, 1])\n",
    "    end\n",
    "    \n",
    "    # Noise\n",
    "    ϵ = rand(Normal(0, std(X*β)*NR), n)\n",
    "    \n",
    "    # Target\n",
    "    y_train = X_train*β + ϵ[index_train]\n",
    "    y_val = X_val*β + ϵ[index_val]\n",
    "    y_test = X_test*β + ϵ[index_test]\n",
    "            \n",
    "    return  (X_train, y_train), (X_val, y_val), (X_test, y_test), β\n",
    "end\n",
    "\n",
    "function get_t_α(n, p, α)\n",
    "    return quantile(TDist(n-p), 1 - α/2)\n",
    "end\n",
    "\n",
    "function get_σ_X(X, y, γ)\n",
    "    n, p = size(X)\n",
    "    \n",
    "    # Estimator σ\n",
    "    M_inv = inv(I/γ + X'X)\n",
    "    σ_tilde = sqrt((y'*(I - X*M_inv*X')*y)/(n-p))\n",
    "    σ_X = σ_tilde * sqrt.(diag(M_inv))\n",
    "    \n",
    "    return σ_X\n",
    "end\n",
    "\n",
    "function get_R2(y_pred, y_true, y_train)\n",
    "    SS_res = norm(y_true .- y_pred)\n",
    "    SS_tot = norm(y_true .- mean(y_train))\n",
    "    return 1 - (SS_res/SS_tot)^2\n",
    "end\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute inner problems and gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Compute g_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function g_s(D_s, b_s, σ_X_s; GD=true)\n",
    "    \n",
    "    # Get length of support of s\n",
    "    l = length(b_s)\n",
    "    if l==0\n",
    "        return zeros(0), 0.0\n",
    "    end\n",
    "    \n",
    "    # Initial solution\n",
    "    λ_s0 = zeros(l) .+ 1.0\n",
    "\n",
    "    # Objective and gradient\n",
    "    function fg!(F, G, λ_s)\n",
    "        \n",
    "        μ_s = λ_s .+ b_s\n",
    "        β_s = D_s*μ_s\n",
    "        \n",
    "        if G != nothing\n",
    "            G .= β_s .- σ_X_s\n",
    "        end\n",
    "        \n",
    "        if F != nothing\n",
    "            return -λ_s'σ_X_s + 0.5*μ_s'β_s\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    lower = zeros(l)\n",
    "    upper = [Inf for _ in 1:l]\n",
    "\n",
    "    res = Optim.optimize(Optim.only_fg!(fg!), lower, upper, λ_s0, \n",
    "        Fminbox(GD ? GradientDescent() : LBFGS()))\n",
    "\n",
    "    return Optim.minimizer(res), - Optim.minimum(res)\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function g_s_gurobi(D_s, b_s, σ_X_s, model)\n",
    "    \n",
    "    # Get length of support of s\n",
    "    l = length(b_s)\n",
    "    if l==0\n",
    "        return zeros(0), 0.0\n",
    "    end\n",
    "\n",
    "    λ_s = model[:λ][1:l]\n",
    "    μ_s = λ_s .+ b_s\n",
    "    β_s = D_s*μ_s\n",
    "    \n",
    "    @objective(model, Max, λ_s'σ_X_s - 0.5*μ_s'β_s)\n",
    "    \n",
    "    optimize!(model)\n",
    "    \n",
    "    value.(λ_s), objective_value(model)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function g_gurobi(supp, Z, D, b, σ_X, model)\n",
    "\n",
    "    # Create DZ once\n",
    "    DZ = D*Z\n",
    "    \n",
    "    λ = model[:λ]\n",
    "    μ = b + λ\n",
    "\n",
    "    @objective(model, Max, λ'*Z*σ_X - 0.5μ'*DZ*μ)\n",
    "    \n",
    "    optimize!(model)\n",
    "    \n",
    "    value.(λ)[supp], objective_value(model)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Compute ∇g_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ∇g_s(supp, supp_c, b, M, λ_s, D_s, σ_X_s)\n",
    "    \n",
    "    β_s = D_s*(b[supp] .+ λ_s)\n",
    "  \n",
    "    grad = zeros(length(b))\n",
    "    grad[supp] = λ_s .* σ_X_s - (β_s .^ 2)/(2γ)\n",
    "    grad[supp_c] = - 0.5*γ*(b[supp_c] - M[supp_c, supp]*β_s).^2\n",
    "    \n",
    "    return grad\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ∇g(supp, D, b, λ_s, σ_X)\n",
    "    \n",
    "    λ = zeros(length(b))\n",
    "    λ[supp] = λ_s\n",
    "    \n",
    "    grad = λ .* σ_X - ((D'*(b + λ)).^ 2)/(2γ)\n",
    "\n",
    "    return grad\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## 3. Compare speed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /!\\ t_α is already in σ_X /!\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_train = 10000\n",
    "n = 2*n_train\n",
    "p = 100\n",
    "k = 10\n",
    "NR = 0.001\n",
    "α = 0.05\n",
    "t_α = get_t_α(n_train, p, α)\n",
    "γ = 1.0\n",
    "\n",
    "# Generate data\n",
    "(X_p, y), _, _, β_true = generate_synthetic_data(n, p, k, NR, seed=42);\n",
    "σ_X_p = t_α * get_σ_X(X_p, y, γ); #t_α is already in σ_X\n",
    "\n",
    "# Compute data in p dimensions\n",
    "M_p = X_p'X_p\n",
    "b_p = X_p'y\n",
    "\n",
    "# Compute data in 2p dimensions\n",
    "M = [M_p -M_p; -M_p  M_p]\n",
    "b = [b_p; -b_p];\n",
    "σ_X = [σ_X_p; σ_X_p] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create s\n",
    "s_true = vcat(β_true .> 0, β_true .< 0) .* 1 \n",
    "supp, supp_c = get_support(s_true)\n",
    "\n",
    "# Get projected variables\n",
    "b_s = b[supp];\n",
    "σ_X_s = σ_X[supp];\n",
    "D_s = inv(I/γ + M[supp, supp]);\n",
    "\n",
    "# Create model for g_s_gurobi\n",
    "model_inner_g_s = create_gurobi_model();\n",
    "@variable(model_inner_g_s, λ[1:k] >= 0)\n",
    "\n",
    "# Create model for g_gurobi\n",
    "model_inner_g = create_gurobi_model();\n",
    "@variable(model_inner_g, λ[1:2p] >= 0);\n",
    "\n",
    "Z = Diagonal(s_true);\n",
    "D = inv(I/γ + Z*M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare g_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ_s_GD, g_s_GD = g_s(D_s, b_s, σ_X_s; GD=true)\n",
    "λ_s_LBFGS, g_s_LBFGS = g_s(D_s, b_s, σ_X_s; GD=false)\n",
    "λ_s_guro_s, g_s_guro_s = g_s_gurobi(D_s, b_s, σ_X_s, model_inner_g_s)\n",
    "λ_s_guro, g_s_guro = g_gurobi(supp, Z, D, b, σ_X, model_inner_g)\n",
    "\n",
    "# Compare objective values\n",
    "println(\"GD: \",g_s_GD)\n",
    "println(\"LBFGS: \",g_s_LBFGS)\n",
    "println(\"Gurobi (g_s): \", g_s_guro_s)\n",
    "println(\"Gurobi (g): \", g_s_guro)\n",
    "\n",
    "# Compare λ\n",
    "hcat(λ_s_GD, λ_s_LBFGS, λ_s_guro_s, λ_s_guro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computational time for D_s compared to D (given s)\n",
    "\n",
    "total_time_D_s = 0\n",
    "total_time_D = 0\n",
    "for _ in 1:1000\n",
    "    \n",
    "    total_time_D_s += @elapsed begin \n",
    "        supp, supp_c = get_support(s_true)\n",
    "        b_s = b[supp];\n",
    "        σ_X_s = σ_X[supp];\n",
    "        D_s = inv(I/γ + M[supp, supp]);\n",
    "    end\n",
    "    \n",
    "    total_time_D += @elapsed begin\n",
    "        Z = Diagonal(s_true);\n",
    "        D = inv(I/γ + Z*M);\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Compute D_s: \", total_time_D_s)\n",
    "println(\"Compute D: \", total_time_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computational time of g_s and g for given D_s or D\n",
    "\n",
    "total_time_GD = 0\n",
    "total_time_LBFGS = 0\n",
    "total_time_Gurobi_g_s = 0\n",
    "total_time_Gurobi_g = 0\n",
    "\n",
    "for _ in 1:1000\n",
    "    total_time_GD += @elapsed g_s(D_s, b_s, σ_X_s; GD=true)\n",
    "    total_time_LBFGS += @elapsed g_s(D_s, b_s, σ_X_s; GD=false)\n",
    "    total_time_Gurobi_g_s += @elapsed g_s_gurobi(D_s, b_s, σ_X_s, model_inner_g_s)\n",
    "    total_time_Gurobi_g += @elapsed g_gurobi(supp, Z, D, b, σ_X, model_inner_g)\n",
    "end\n",
    "\n",
    "println(\"Optim.jl + GD: \",total_time_GD)\n",
    "println(\"Optim.jl + LBFGS: \", total_time_LBFGS)\n",
    "println(\"Gurobi g_s (model created outside): \", total_time_Gurobi_g_s)\n",
    "println(\"Gurobi g (model created outside): \", total_time_Gurobi_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ∇g_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare the gradient for different optimal lambdas\n",
    "\n",
    "∇g_s_guro = ∇g_s(supp, supp_c, b, M, λ_s_guro, D_s, σ_X_s)\n",
    "∇g_s_GD = ∇g_s(supp, supp_c, b, M, λ_s_GD, D_s, σ_X_s)\n",
    "∇g_guro = ∇g(supp, D, b, λ_s_guro, σ_X)\n",
    "\n",
    "println(\"|| ∇g_s_guro - ∇g_s_GD || =  \", norm(∇g_s_guro - ∇g_s_GD))\n",
    "println(\"|| ∇g_s_guro - ∇g_guro || =  \", norm(∇g_s_guro - ∇g_guro))\n",
    "hcat(∇g_s_GD, ∇g_s_guro, ∇g_guro)[1:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computational time for D_s compared to D (given s)\n",
    "\n",
    "total_time_∇g_s = 0\n",
    "total_time_∇g = 0\n",
    "\n",
    "for _ in 1:1000\n",
    "    \n",
    "    total_time_∇g_s += @elapsed begin \n",
    "        ∇g_s(supp, supp_c, b, M, λ_s_GD, D_s, σ_X_s)\n",
    "    end\n",
    "    \n",
    "    total_time_∇g += @elapsed begin\n",
    "        ∇g(supp, D, b, λ_s_GD, σ_X)\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Compute ∇g_s: \", total_time_∇g_s)\n",
    "println(\"Compute ∇g: \", total_time_∇g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## 4. Compute Cutting plane algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_primal (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_primal(X, y, k, γ, σ_X; TimeLimit=-1, LogFile=nothing)\n",
    "    \n",
    "    n, p = size(X)\n",
    "    \n",
    "    model = create_gurobi_model(;LogFile=LogFile, TimeLimit=TimeLimit)\n",
    "\n",
    "    # TODO: change big-M values\n",
    "    M1 = 1000\n",
    "    M2 = 1000\n",
    "\n",
    "    @variable(model, β[i=1:p])\n",
    "    @variable(model, s[i=1:p], Bin)\n",
    "    @variable(model, b[i=1:p], Bin)\n",
    "\n",
    "    @constraint(model, sum(s) <= k)\n",
    "    \n",
    "    @constraint(model, [i=1:p], β[i] <= M1*s[i])\n",
    "    @constraint(model, [i=1:p], β[i] >= -M1*s[i])\n",
    "\n",
    "    @constraint(model, [i=1:p], β[i]/σ_X[i] + M2*b[i] >= s[i])\n",
    "    @constraint(model, [i=1:p], -β[i]/σ_X[i] + M2*(1-b[i]) >= s[i])\n",
    "\n",
    "    yty = y'y\n",
    "    XtX = X'X\n",
    "    ytX = y'X\n",
    "    \n",
    "    @objective(model, Min, 0.5*(yty - 2*ytX*β + β'*XtX*β + (1/γ)*sum(β[j]^2 for j=1:p)))\n",
    "        \n",
    "    JuMP.optimize!(model)\n",
    "    \n",
    "    return objective_value(model), value.(β)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_warm_start_primal (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_warm_start_primal(X, y, k, γ, σ_X, time_limit; LogFile=nothing)\n",
    "    \n",
    "    n, p = size(X)\n",
    "    \n",
    "    model = create_gurobi_model(;TimeLimit=time_limit, LogFile=LogFile)\n",
    "\n",
    "    # TODO: change big-M values\n",
    "    M1 = 1000\n",
    "    M2 = 1000\n",
    "\n",
    "    @variable(model, β[i=1:p])\n",
    "    @variable(model, s[i=1:p], Bin)\n",
    "    @variable(model, b[i=1:p], Bin)\n",
    "\n",
    "    @constraint(model, sum(s) <= k)\n",
    "    \n",
    "    @constraint(model, [i=1:p], β[i] <= M1*s[i])\n",
    "    @constraint(model, [i=1:p], β[i] >= -M1*s[i])\n",
    "\n",
    "    @constraint(model, [i=1:p], β[i]/σ_X[i] + M2*b[i] >= s[i])\n",
    "    @constraint(model, [i=1:p], -β[i]/σ_X[i] + M2*(1-b[i]) >= s[i])\n",
    "\n",
    "    yty = y'y\n",
    "    XtX = X'X\n",
    "    ytX = y'X\n",
    "    \n",
    "    @objective(model, Min, 0.5*(yty - 2*ytX*β + β'*XtX*β + (1/γ)*sum(β[j]^2 for j=1:p)))\n",
    "    \n",
    "    JuMP.optimize!(model)\n",
    "    \n",
    "    s_val = Int.(value.(s))\n",
    "    b_val = Int.(value.(b))\n",
    "    \n",
    "    return vcat(s_val .* (b_val .== 0), s_val .* (b_val .== 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_dual (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_dual(X_p, y, k, γ, σ_X_p; LogFile=nothing, WarmStart=nothing, TimeLimit=-1)\n",
    "    \"\"\"\n",
    "    WarmStart ∈ {  nothing, :RidgeStart, :PrimalStart }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get dimensions\n",
    "    n, p = size(X_p)\n",
    "    \n",
    "    # Constant\n",
    "    C = 0.5*y'y #TODO: add it in the objecive in the end\n",
    " \n",
    "    # Compute data in p dimensions\n",
    "    M_p = X_p'X_p\n",
    "    b_p = X_p'y\n",
    "\n",
    "    # Compute data in 2p dimensions\n",
    "    M = [M_p -M_p; -M_p  M_p]\n",
    "    b = [b_p; -b_p];\n",
    "    σ_X = [σ_X_p; σ_X_p] ;\n",
    "    \n",
    "    # Outer problem\n",
    "    miop = create_gurobi_model(;LogFile=LogFile, TimeLimit=TimeLimit)\n",
    "    @variable(miop, s[1:2p], Bin)\n",
    "    @variable(miop, t >= -C)\n",
    "    @constraint(miop, sum(s) <= k)\n",
    "    @constraint(miop, [i=1:p], s[i]+s[p+i]<=1)\n",
    "    \n",
    "    # Initial solution\n",
    "    s0 = zeros(2p) #TODO: change this\n",
    "    \n",
    "    # a. First k values\n",
    "    s0[1:k] .= 1\n",
    "    \n",
    "    # b. Ridge regression\n",
    "    if (WarmStart == :RidgeStart)\n",
    "        println(\"Ridge Warm Start.\")\n",
    "        β_ridge = inv(I/γ + M_p)*b_p\n",
    "        s0[findall(x -> x>0, β_ridge)] .= 1.0\n",
    "        s0[findall(x -> x<0, β_ridge) .+ p] .= 1.0\n",
    "    end\n",
    "    \n",
    "    # c. Primal solution + Time limit\n",
    "    if (WarmStart == :PrimalStart)\n",
    "        println(\"Primal Warm Start.\")\n",
    "        s0 = compute_warm_start_primal(X_p, y, k, γ, σ_X, 20; LogFile=LogFile)\n",
    "    end\n",
    "\n",
    "    # Initial cut\n",
    "    supp, supp_c = get_support(s0)\n",
    "    \n",
    "    D_s, b_s, σ_X_s = inv(I/γ + M[supp, supp]), b[supp], σ_X[supp]\n",
    "    \n",
    "    λ_s0, g_s0 = g_s(D_s, b_s, σ_X_s; GD=true)\n",
    "    ∇g_s0 = ∇g_s(supp, supp_c, b, M, λ_s0, D_s, σ_X_s)\n",
    "    \n",
    "    @constraint(miop, t >= g_s0 + dot(∇g_s0, s - s0))\n",
    "    @objective(miop, Min, t + C)\n",
    "    \n",
    "    # Cutting planes    \n",
    "    function outer_approximation(cb_data)\n",
    "        \n",
    "        s_val = [callback_value(cb_data, s[i]) for i=1:2p]\n",
    "        \n",
    "        supp, supp_c = get_support(s_val)\n",
    "\n",
    "        D_s, b_s, σ_X_s = inv(I/γ + M[supp, supp]), b[supp], σ_X[supp]\n",
    "\n",
    "        λ_s_val, g_s_val = g_s(D_s, b_s, σ_X_s; GD=true)\n",
    "        ∇g_s_val = ∇g_s(supp, supp_c, b, M, λ_s_val, D_s, σ_X_s)\n",
    "        \n",
    "        con = @build_constraint(t >= g_s_val + dot(∇g_s_val, s - s_val))\n",
    "        MOI.submit(miop, MOI.LazyConstraint(cb_data), con)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    MOI.set(miop, MOI.LazyConstraintCallback(), outer_approximation)\n",
    "    JuMP.optimize!(miop)\n",
    "    \n",
    "    \n",
    "    s_opt = JuMP.value.(miop[:s])\n",
    "    supp, supp_c = get_support(s_opt)\n",
    "    \n",
    "    D_s, b_s, σ_X_s = inv(I/γ + M[supp, supp]), b[supp], σ_X[supp]\n",
    "    \n",
    "    λ_s_opt, g_s_opt = g_s(D_s, b_s, σ_X_s; GD=true)\n",
    "    \n",
    "    β = zeros(2p)\n",
    "    β[supp] = D_s*(λ_s_opt + b_s)\n",
    "    \n",
    "\n",
    "    return objective_value(miop), β[1:p] - β[p+1:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogFile: nouveau_debug.txt.\n",
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (mac64)\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "Optimize a model with 401 rows, 300 columns and 1100 nonzeros\n",
      "Model fingerprint: 0x856b654d\n",
      "Model has 5050 quadratic objective terms\n",
      "Variable types: 100 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [1e-02, 1e+00]\n",
      "  QObjective range [5e-06, 2e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 1e+03]\n",
      "Found heuristic solution: objective 9.3237205\n",
      "Presolve time: 0.00s\n",
      "Presolved: 401 rows, 300 columns, 1100 nonzeros\n",
      "Presolved model has 5050 quadratic objective terms\n",
      "Variable types: 100 continuous, 200 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 6.418095e+00, 586 iterations, 0.03 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    6.41809    0  154    9.32372    6.41809  31.2%     -    0s\n",
      "H    0     0                       8.6539850    6.41809  25.8%     -    0s\n",
      "H    0     0                       8.1258244    6.41809  21.0%     -    0s\n",
      "H    0     0                       7.3504023    6.41809  12.7%     -    0s\n",
      "H    0     0                       7.0031171    6.41809  8.35%     -    0s\n",
      "     0     2    6.41809    0  154    7.00312    6.41809  8.35%     -    0s\n",
      " 21188  7913     cutoff   27         7.00312    6.64709  5.08%   8.3    5s\n",
      " 47108 13891     cutoff   39         7.00312    6.75903  3.49%   8.1   10s\n",
      " 68081 17331    6.99977   26  133    7.00312    6.80257  2.86%   7.9   15s\n",
      " 88245 19394    6.88837   29  134    7.00312    6.83351  2.42%   7.7   20s\n",
      "\n",
      "Explored 93201 nodes (713556 simplex iterations) in 20.88 seconds\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 5: 7.00312 7.3504 8.12582 ... 9.32372\n",
      "\n",
      "Solve interrupted\n",
      "Best objective 7.003117132665e+00, best bound 6.840056952805e+00, gap 2.3284%\n",
      "\n",
      "User-callback calls 185383, time in user-callback 0.03 sec\n",
      " 37.067970 seconds (53.57 M allocations: 2.724 GiB, 5.02% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.003117132664962, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.541392  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43268])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time primal_obj, β_primal = compute_primal(X_p, y, k, γ, σ_X_p; LogFile=\"nouveau_debug.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogFile: nouveau_debug.txt.\n",
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (mac64)\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "Optimize a model with 102 rows, 201 columns and 601 nonzeros\n",
      "Model fingerprint: 0x67ec7ced\n",
      "Variable types: 1 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-07, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [9e+00, 9e+00]\n",
      "  RHS range        [2e-01, 1e+01]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 102 rows, 201 columns, 601 nonzeros\n",
      "Variable types: 1 continuous, 200 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 4.903410e+00, 26 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    4.97558    0    2          -    4.97558      -     -    0s\n",
      "H    0     0                       8.0736847    4.97558  38.4%     -    0s\n",
      "H    0     0                       7.2691461    4.97558  31.6%     -    0s\n",
      "     0     2    6.69967    0    3    7.26915    6.69967  7.83%     -    0s\n",
      "*  820   373              10       7.0031171    6.89049  1.61%   3.8    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Lazy constraints: 86\n",
      "\n",
      "Explored 1057 nodes (3737 simplex iterations) in 0.66 seconds\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 3: 7.00312 7.26915 8.07368 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.003117132665e+00, best bound 7.003117132665e+00, gap 0.0000%\n",
      "\n",
      "User-callback calls 2300, time in user-callback 0.63 sec\n",
      "  7.036671 seconds (20.47 M allocations: 1.048 GiB, 11.50% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.003117132664963, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.541392  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43268])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time dual_obj, β_dual = compute_dual(X_p, y, k, γ, σ_X_p; LogFile=\"nouveau_debug.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×3 Array{Float64,2}:\n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 1.0  0.541392  0.541392\n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " ⋮                      \n",
       " 0.0  0.0       0.0     \n",
       " 1.0  0.44302   0.44302 \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 0.0  0.0       0.0     \n",
       " 1.0  0.43268   0.43268 "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcat(β_true, β_primal, β_dual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## 5. Experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_train = 10000\n",
    "n = 2*n_train\n",
    "NR = 0.001\n",
    "α = 0.05;\n",
    "t_max = 30*60 # 30 min max per solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = \"results/2021_03_06_results.csv\"\n",
    "logfile = \"results/2021_03_06_logs.txt\"\n",
    "\n",
    "write_list(csv_path, [\"Algo\", \"Seed\", \"n\", \"p\", \"k_true\", \"k\", \"γ\", \n",
    "                      \"NR\", \"α\", \"R2\", \"OR2\", \"t_algo\", \"t_data\", \"t_variance\"])\n",
    "\n",
    "for seed ∈ [1997, 1998]\n",
    "    for p ∈ [100, 150, 200, 300]\n",
    "\n",
    "        # True sparsity\n",
    "        k_true = div(p, 10)\n",
    "\n",
    "        # Generate data\n",
    "        t_data = @elapsed (X_train, y_train), _, (X_test, y_test), β_true = generate_synthetic_data(n, p, k_true, NR, seed=seed);\n",
    "\n",
    "        # Significance\n",
    "        t_variance = @elapsed t_α = get_t_α(n_train, p, α)\n",
    "        \n",
    "        # Robustness\n",
    "        for γ ∈ [1.0, 10.0, 100.0]\n",
    "            \n",
    "            # Variance\n",
    "            t_variance += @elapsed σ_X = t_α * get_σ_X(X_train, y_train, γ)\n",
    "        \n",
    "            # Estimated sparsity\n",
    "            Random.seed!(seed)\n",
    "            k = rand(5:15)\n",
    "            \n",
    "            # Dual\n",
    "            t_dual = @elapsed obj_dual, β_dual = compute_dual(X_train, y_train, k, γ, σ_X; LogFile=logfile, TimeLimit=t_max);\n",
    "            R2_dual = get_R2(X_train*β_dual, y_train, y_train)\n",
    "            OR2_dual = get_R2(X_test*β_dual, y_test, y_train)\n",
    "            write_list(csv_path, [\"dual\", seed, n_train, p, k_true, k, γ, \n",
    "                                  NR, α, R2_dual, OR2_dual, t_dual, t_data, t_variance])\n",
    "            \n",
    "            # Primal\n",
    "            t_primal = @elapsed obj_primal, β_primal = compute_primal(X_train, y_train, k, γ, σ_X; LogFile=logfile, TimeLimit=t_max);\n",
    "            R2_primal = get_R2(X_train*β_primal, y_train, y_train)\n",
    "            OR2_primal = get_R2(X_test*β_primal, y_test, y_train)\n",
    "            write_list(csv_path, [\"primal\", seed, n_train, p, k_true, k, γ, \n",
    "                                  NR, α, R2_primal, OR2_primal, t_primal, t_data, t_variance])\n",
    "            \n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
