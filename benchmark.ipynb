{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Distributions\n",
    "using LinearAlgebra\n",
    "using Gurobi, JuMP\n",
    "using DataFrames\n",
    "using CSV\n",
    "using StatsBase\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "# Create a gurobi model without the annoying academic license message\n",
    "gurobi_env = Gurobi.Env()\n",
    "function create_gurobi_model(; TimeLimit=-1, LogFile=nothing)\n",
    "    model = Model(optimizer_with_attributes(() -> Gurobi.Optimizer(gurobi_env)));\n",
    "    if TimeLimit >= 0\n",
    "        println(\"Set Gurobi TimeLimit.\")\n",
    "        set_optimizer_attribute(model, \"TimeLimit\", TimeLimit)\n",
    "    end\n",
    "    if LogFile != nothing\n",
    "        println(\"LogFile: $(LogFile).\")\n",
    "        set_optimizer_attribute(model, \"LogFile\", LogFile)\n",
    "    else\n",
    "        set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "    end\n",
    "    set_optimizer_attribute(model, \"NumericFocus\", 3)\n",
    "    set_optimizer_attribute(model, \"Threads\", 4)\n",
    "    return model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "# Dual Holistic Regression | Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_primal (generic function with 1 method)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_primal(X, y, k, γ, t_α, σ_X)\n",
    "    \n",
    "    n, p = size(X)\n",
    "    \n",
    "    model = create_gurobi_model(LogFile=\"primal.txt\")\n",
    "\n",
    "    # TODO: change big-M values\n",
    "    M1 = 1000\n",
    "    M2 = 1000\n",
    "\n",
    "    @variable(model, β[i=1:p])\n",
    "    @variable(model, s[i=1:p], Bin)\n",
    "    @variable(model, b[i=1:p], Bin)\n",
    "\n",
    "    @constraint(model, sum(s) <= k)\n",
    "    \n",
    "    @constraint(model, [i=1:p], β[i] <= M1*s[i])\n",
    "    @constraint(model, [i=1:p], β[i] >= -M1*s[i])\n",
    "\n",
    "    @constraint(model, [i=1:p], β[i]/σ_X[i] + M2*b[i] >= t_α*s[i])\n",
    "    @constraint(model, [i=1:p], -β[i]/σ_X[i] + M2*(1-b[i]) >= t_α*s[i])\n",
    "\n",
    "    @objective(model, Min, 0.5*sum((y[i] - X[i,:]'β)^2 for i=1:n) + (0.5/γ)* sum(β[j]^2 for j=1:p))\n",
    "    optimize!(model)\n",
    "    \n",
    "    return objective_value(model), value.(β)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g (generic function with 1 method)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function g(s, X, y, D, Z, γ, t_α, σ_X)\n",
    "    \n",
    "    # Get size\n",
    "    n, p = size(X)\n",
    "    \n",
    "    # Compute norm\n",
    "    function compute_DZ_square_norm(in_norm)\n",
    "        return in_norm' * D*Z * in_norm\n",
    "    end\n",
    "    \n",
    "    # Compute max\n",
    "    model = create_gurobi_model()\n",
    "    @variable(model, λ[1:p] >= 0)\n",
    "    \n",
    "    obj_1 = 0.5*y'y\n",
    "    obj_2 = t_α*λ'*(s.*σ_X)\n",
    "    obj_3 = - 0.5 * compute_DZ_square_norm(X'y + λ)\n",
    "    @objective(model, Max, obj_1 + obj_2 + obj_3)\n",
    "\n",
    "    optimize!(model)\n",
    "\n",
    "    # Compute β\n",
    "    sparsity_indexes = findall(x->x>0, s)\n",
    "    X_s = X[:, sparsity_indexes]\n",
    "    λ_s = value.(λ)[sparsity_indexes]\n",
    "    β_s = (I/γ + X_s'X_s)^(-1)*(X_s'y + λ_s)\n",
    "    \n",
    "    β_pred = zeros(p)\n",
    "    β_pred[sparsity_indexes] = β_s\n",
    "    return β_pred, value.(λ), objective_value(model)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇g (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ∇g(s, λ, X, y, D, t_α, σ_X)\n",
    "    n,p = size(X)\n",
    "    grad = zeros(p)\n",
    "    \n",
    "    function compute_DED_square_norm(E,in_norm)\n",
    "        return in_norm' * D*E*D' * in_norm\n",
    "    end\n",
    "    for i in 1:p\n",
    "        E_ii = Diagonal([(j == i)*1 for j in 1:p])\n",
    "        grad[i] = t_α*λ'E_ii*σ_X - 0.5*compute_DED_square_norm(E_ii, X'y+ λ)\n",
    "    end\n",
    "    return grad\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_dual (generic function with 1 method)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_dual(X_p, y, k, γ, t_α, σ_X_p)\n",
    "    n, p = size(X_p)\n",
    "    \n",
    "    # Extended Matrices\n",
    "    X = hcat(X_p, -X_p)\n",
    "    M = X'X\n",
    "    σ_X = [σ_X_p; σ_X_p]\n",
    "    \n",
    "    # Outer problem\n",
    "    miop = create_gurobi_model(LogFile=\"Dual.txt\")\n",
    "    \n",
    "    @variable(miop, s[1:2*p], Bin)\n",
    "    @variable(miop, t >= 0)\n",
    "    \n",
    "    @constraint(miop, sum(s) <= k)\n",
    "    @constraint(miop, [i=1:p], s[i]+s[p+i]<=1)\n",
    "    \n",
    "    # Cutting plane\n",
    "    \n",
    "    s_init = zeros(2*p)\n",
    "    s_init[1:k] .= 1\n",
    "    Z_init = Diagonal(s_init)\n",
    "    D_init = (I/γ + Z_init*M)^(-1)\n",
    "    \n",
    "    β_init, λ_init, g_init = g(s_init, X, y, D_init, Z_init, γ, t_α, σ_X)\n",
    "    ∇g_init = ∇g(s_init, λ_init, X, y, D_init, t_α, σ_X)\n",
    "    \n",
    "    @constraint(miop, t >= g_init + dot(∇g_init, s - s_init))\n",
    "    @objective(miop, Min, t)\n",
    "    \n",
    "    function outer_approximation(cb_data)\n",
    "        s_val = [callback_value(cb_data, s[i]) for i=1:2*p]\n",
    "        Z_val = Diagonal(s_val)\n",
    "        D_val = (I/γ + Z_val*M)^(-1)\n",
    "\n",
    "        β_val, λ_val, g_val = g(s_val, X, y, D_val, Z_val, γ, t_α, σ_X)\n",
    "        ∇g_val = ∇g(s_val, λ_val, X, y, D_val, t_α, σ_X)\n",
    "        \n",
    "        offset = sum(∇g_val .* s_val)\n",
    "        con = @build_constraint(t >= g_val + ∇g_val'*s - offset)\n",
    "        MOI.submit(miop, MOI.LazyConstraint(cb_data), con)\n",
    "    end\n",
    "    \n",
    "    MOI.set(miop, MOI.LazyConstraintCallback(), outer_approximation)\n",
    "    optimize!(miop)\n",
    "    \n",
    "    s_val = JuMP.value.(s)\n",
    "    Z_val = Diagonal(s_val)\n",
    "    D_val = (I/γ + Z_val*M)^(-1)\n",
    "    β_val, λ_val, g_val = g(s_val, X, y, D_val, Z_val, γ, t_α, σ_X)\n",
    "\n",
    "    β_pred = β_val[1:p] .- β_val[p+1:end]\n",
    "    return objective_value(miop), β_pred \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_synthetic_data (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_synthetic_data(n, p, k, NR)\n",
    "    \n",
    "    # Generate PD matrix\n",
    "    A = randn(p, p)\n",
    "    A = A'*A\n",
    "    Σ = (A' + A)/2\n",
    "    \n",
    "    # Generate data X\n",
    "    d = MvNormal(Σ)\n",
    "    X = rand(d, n)'I\n",
    "    \n",
    "    # Split data\n",
    "    index_train = 1:floor(Int, 0.5*n)\n",
    "    index_val = floor(Int, 0.5*n)+1:floor(Int, 0.75*n)\n",
    "    index_test = floor(Int, 0.75*n)+1:n\n",
    "    \n",
    "    X_train = X[index_train,:]\n",
    "    X_val = X[index_val,:]\n",
    "    X_test = X[index_test,:]\n",
    "    \n",
    "    # Center\n",
    "    μ_train = [mean(X_train[:, j]) for j=1:p]\n",
    "    for j=1:p\n",
    "         X_train[:,j] = X_train[:,j] .- μ_train[j]\n",
    "         X_val[:,j] = X_val[:,j] .- μ_train[j]\n",
    "         X_test[:,j] = X_test[:,j] .- μ_train[j]\n",
    "    end\n",
    "    \n",
    "    # Scale\n",
    "    σ_train = [norm(X_train[:, j]) for j=1:p]\n",
    "    for j=1:p\n",
    "         X_train[:,j] = X_train[:,j]/σ_train[j]\n",
    "         X_val[:,j] = X_val[:,j] ./ σ_train[j]\n",
    "         X_test[:,j] = X_test[:,j] ./ σ_train[j]\n",
    "    end\n",
    "    \n",
    "    # Generate β\n",
    "    β = zeros(p)\n",
    "    for j=1:k\n",
    "        β[floor(Int, j*p/k)] = 1.0*rand([-1, 1])\n",
    "    end\n",
    "    \n",
    "    # Noise\n",
    "    ϵ = rand(Normal(0, std(X*β)*NR), n)\n",
    "    \n",
    "    # Target\n",
    "    y_train = X_train*β + ϵ[index_train]\n",
    "    y_val = X_val*β + ϵ[index_val]\n",
    "    y_test = X_test*β + ϵ[index_test]\n",
    "            \n",
    "    return  (X_train, y_train), (X_val, y_val), (X_test, y_test), β\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_t_α_and_σ_X (generic function with 1 method)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_t_α_and_σ_X(X, y, α, γ)\n",
    "    n, p = size(X)\n",
    "    \n",
    "    # Student law\n",
    "    t_α = quantile(TDist(n-p), 1 - α/2) # Beware: n-p-1 if we add intercept\n",
    "    \n",
    "    # Estimator σ\n",
    "    M = 1/γ*I + X'X\n",
    "    M_inv = M^-1\n",
    "    σ_tilde = sqrt((y'*(I - X*M_inv*X')*y)/(n-p))\n",
    "    σ_X = σ_tilde * sqrt.(diag(M_inv))\n",
    "    \n",
    "    return t_α, σ_X\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_OR2 (generic function with 1 method)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_insample_R2(y_pred, y_true)\n",
    "    TSE = sum((y_pred[i]-y_true[i])^2 for i=1:p)\n",
    "    baseline_E = sum((sum(y_true)/length(y_true)-y_true[i])^2 for i=1:p)\n",
    "    return 1 - TSE/baseline_E\n",
    "end\n",
    "\n",
    "function get_OR2(y_pred, y_true, y_train)\n",
    "    TSE = sum((y_pred[i]-y_true[i])^2 for i=1:p)\n",
    "    baseline_E = sum((sum(y_train)/length(y_train)-y_true[i])^2 for i=1:p)\n",
    "    return 1 - TSE/baseline_E\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2*10000\n",
    "p = 100\n",
    "k = 10\n",
    "NR = 0.01\n",
    "α = 0.05\n",
    "γ = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test), β_true = generate_synthetic_data(n, p, k, NR);\n",
    "#plot(X_train * β_true)\n",
    "#plot!(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9602036366973514, [0.253312, 0.249033, 0.247697, 0.249637, 0.253438, 0.254417, 0.255556, 0.256276, 0.24951, 0.250361  …  0.250722, 0.254481, 0.254193, 0.25591, 0.253394, 0.249383, 0.254676, 0.250558, 0.250814, 0.250729])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_α, σ_X = get_t_α_and_σ_X(X_train, y_train, α, γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogFile: primal.txt.\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 401 rows, 300 columns and 1100 nonzeros\n",
      "Model fingerprint: 0x531e0ae2\n",
      "Model has 5050 quadratic objective terms\n",
      "Variable types: 100 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [6e-04, 2e+00]\n",
      "  QObjective range [1e-04, 2e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+01, 1e+03]\n",
      "Found heuristic solution: objective 514.1270556\n",
      "Presolve time: 0.00s\n",
      "Presolved: 401 rows, 300 columns, 1100 nonzeros\n",
      "Presolved model has 5050 quadratic objective terms\n",
      "Variable types: 100 continuous, 200 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 5.085777e+02, 1393 iterations, 0.17 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  508.57772    0  137  514.12706  508.57772  1.08%     -    0s\n",
      "H    0     0                     510.7748542  508.57772  0.43%     -    0s\n",
      "     0     2  508.57772    0  137  510.77485  508.57772  0.43%     -    0s\n",
      "H  255    93                     510.7454942  508.66084  0.41%  12.8    0s\n",
      "H  322    91                     510.6344031  508.66084  0.39%  12.5    0s\n",
      "  4057  1108     cutoff   34       510.63440  508.68837  0.38%  11.3    5s\n",
      " 10801  5418  509.21403   26  128  510.63440  508.80081  0.36%  10.6   10s\n",
      " 17930  9657  509.64726   29  122  510.63440  508.85236  0.35%  10.7   15s\n",
      " 25494 13961  509.66006   31  116  510.63440  508.91545  0.34%  10.8   20s\n",
      " 32988 18053  509.93594   38  113  510.63440  508.97063  0.33%  10.8   25s\n",
      " 39081 20989  509.55548   32  115  510.63440  509.00843  0.32%  10.8   30s\n",
      " 43227 23266  509.97424   36  115  510.63440  509.02341  0.32%  10.9   35s\n",
      " 49465 25999  509.50285   34  118  510.63440  509.04876  0.31%  10.9   40s\n",
      " 55059 29018  509.50731   28  122  510.63440  509.07144  0.31%  10.9   45s\n",
      " 61747 32486  509.56848   29  126  510.63440  509.08976  0.30%  10.9   50s\n",
      " 67769 35465     cutoff   51       510.63440  509.10853  0.30%  10.9   55s\n",
      " 75451 39356     cutoff   27       510.63440  509.12896  0.29%  10.9   60s\n",
      " 81851 42481  509.81673   35  116  510.63440  509.14284  0.29%  10.9   65s\n",
      " 88581 45751     cutoff   51       510.63440  509.15929  0.29%  10.9   70s\n",
      " 92716 47778     cutoff   44       510.63440  509.16859  0.29%  10.9   75s\n",
      " 99807 51531  509.53564   28  124  510.63440  509.17990  0.28%  10.9   80s\n",
      " 106460 54437  510.29778   31  122  510.63440  509.19358  0.28%  10.9   85s\n",
      " 113731 58044  510.28887   47   96  510.63440  509.20744  0.28%  10.8   90s\n",
      " 120734 61392  509.56676   29  120  510.63440  509.22035  0.28%  10.8   95s\n",
      " 127405 64610  510.21333   38  116  510.63440  509.23315  0.27%  10.8  100s\n",
      " 135200 68382  509.45881   30  122  510.63440  509.24653  0.27%  10.8  105s\n",
      " 142406 72179  510.59401   48   95  510.63440  509.25816  0.27%  10.8  110s\n",
      " 148210 74842  509.36804   27  128  510.63440  509.26664  0.27%  10.8  115s\n",
      " 153215 77447     cutoff   25       510.63440  509.27357  0.27%  10.8  120s\n",
      " 160604 81023  509.48506   38  112  510.63440  509.28197  0.26%  10.8  125s\n",
      " 166021 83563  510.59318   62   83  510.63440  509.28893  0.26%  10.8  130s\n",
      " 172060 86632  510.03148   32  117  510.63440  509.29517  0.26%  10.8  135s\n",
      " 176666 88813     cutoff   44       510.63440  509.30094  0.26%  10.8  140s\n",
      " 182672 91490  510.45771   40  109  510.63440  509.30840  0.26%  10.8  145s\n",
      " 188693 94201  509.31921   28  119  510.63440  509.31440  0.26%  10.8  150s\n",
      " 193811 96533  510.29422   41  111  510.63440  509.32044  0.26%  10.8  155s\n",
      " 200390 99486  510.31667   42  100  510.63440  509.32738  0.26%  10.8  160s\n",
      " 206889 102220  510.07641   34  113  510.63440  509.33401  0.25%  10.8  165s\n",
      " 214942 106034  510.16535   39  113  510.63440  509.34231  0.25%  10.8  170s\n",
      " 219717 108216  509.73021   29  123  510.63440  509.34809  0.25%  10.8  175s\n",
      " 226924 111554  510.18784   33  116  510.63440  509.35487  0.25%  10.8  180s\n",
      " 233458 114546  510.10150   38  112  510.63440  509.36013  0.25%  10.8  185s\n",
      " 240600 117691     cutoff   42       510.63440  509.36696  0.25%  10.8  190s\n",
      " 248565 121104  509.81999   46  104  510.63440  509.37548  0.25%  10.8  195s\n",
      " 256295 124185  509.60447   26  123  510.63440  509.38117  0.25%  10.8  200s\n",
      " 263797 127300  509.99696   30  122  510.63440  509.38831  0.24%  10.8  205s\n",
      " 269806 130041     cutoff   45       510.63440  509.39213  0.24%  10.8  210s\n",
      " 277711 133276  509.98051   36  111  510.63440  509.39832  0.24%  10.7  215s\n",
      " 285486 136570     cutoff   54       510.63440  509.40333  0.24%  10.7  220s\n",
      " 292496 139640     cutoff   46       510.63440  509.40837  0.24%  10.7  225s\n",
      " 299786 142814  509.75999   31  121  510.63440  509.41286  0.24%  10.7  230s\n",
      " 305958 145772     cutoff   37       510.63440  509.41692  0.24%  10.7  235s\n",
      " 313175 148911  509.97909   35  117  510.63440  509.42127  0.24%  10.7  240s\n",
      " 320094 152078  510.43566   42  114  510.63440  509.42575  0.24%  10.7  245s\n",
      " 327361 155118     cutoff   29       510.63440  509.43000  0.24%  10.7  250s\n",
      " 333947 158060     cutoff   31       510.63440  509.43394  0.24%  10.7  255s\n",
      " 337455 159580  510.17203   40  107  510.63440  509.43614  0.23%  10.7  261s\n",
      " 340437 160973  510.11338   33  120  510.63440  509.43804  0.23%  10.7  266s\n",
      " 343306 162262  510.46801   53   90  510.63440  509.44002  0.23%  10.7  271s\n",
      " 347738 164278  509.73658   30  126  510.63440  509.44248  0.23%  10.7  275s\n",
      " 351464 165858  509.44660   27  126  510.63440  509.44447  0.23%  10.7  280s\n",
      " 356244 168192  510.50499   49   90  510.63440  509.44696  0.23%  10.7  285s\n",
      " 360990 170138  510.24360   39  110  510.63440  509.45016  0.23%  10.7  290s\n",
      " 367013 172855  510.54698   55   90  510.63440  509.45355  0.23%  10.7  295s\n",
      " 372293 175192  509.45867   26  127  510.63440  509.45630  0.23%  10.7  300s\n",
      " 378126 177574  510.25625   43  105  510.63440  509.46004  0.23%  10.7  305s\n",
      " 383586 180012  510.19498   33  119  510.63440  509.46327  0.23%  10.7  310s\n",
      " 390949 182984  510.11646   33  125  510.63440  509.46737  0.23%  10.7  315s\n",
      " 397138 185717  510.20975   42  110  510.63440  509.47096  0.23%  10.7  320s\n",
      " 403826 188528  509.95174   35  118  510.63440  509.47493  0.23%  10.7  325s\n",
      " 410347 191240  509.72932   32  123  510.63440  509.47828  0.23%  10.7  330s\n",
      " 416958 193865  510.51718   45   98  510.63440  509.48157  0.23%  10.7  335s\n",
      " 423605 196686     cutoff   28       510.63440  509.48488  0.23%  10.7  340s\n",
      " 430668 199600  509.69819   29  121  510.63440  509.48814  0.22%  10.7  345s\n",
      " 436460 201839  510.02791   31  115  510.63440  509.49105  0.22%  10.7  350s\n",
      " 443807 204816  510.57072   33  118  510.63440  509.49478  0.22%  10.7  355s\n",
      " 451015 207693  510.42775   42  114  510.63440  509.49791  0.22%  10.7  360s\n",
      " 458855 210879     cutoff   49       510.63440  509.50137  0.22%  10.7  365s\n",
      " 466008 213832  510.62235   47   99  510.63440  509.50449  0.22%  10.7  370s\n",
      " 470665 215745     cutoff   29       510.63440  509.50645  0.22%  10.7  375s\n",
      " 476030 218046  510.31913   38  116  510.63440  509.50847  0.22%  10.7  380s\n",
      " 482749 220833  509.81497   35  118  510.63440  509.51172  0.22%  10.7  385s\n",
      " 489310 223694  510.30908   40  105  510.63440  509.51465  0.22%  10.7  390s\n",
      " 495958 226297     cutoff   42       510.63440  509.51743  0.22%  10.7  395s\n",
      " 503659 229381     cutoff   39       510.63440  509.52051  0.22%  10.7  400s\n",
      " 511437 232641  509.52396   27  132  510.63440  509.52384  0.22%  10.7  405s\n",
      " 519241 235687     cutoff   48       510.63440  509.52716  0.22%  10.6  410s\n",
      " 526345 238456  509.78092   30  119  510.63440  509.53032  0.22%  10.6  415s\n",
      " 534199 241716  510.43426   43  110  510.63440  509.53344  0.22%  10.6  420s\n",
      " 541768 244867  509.53752   29  120  510.63440  509.53629  0.22%  10.6  425s\n",
      " 548435 247679  510.12251   38  109  510.63440  509.53856  0.21%  10.6  430s\n",
      " 555739 250789  509.82766   35  117  510.63440  509.54119  0.21%  10.6  435s\n",
      " 563509 254021  509.54401   22  126  510.63440  509.54389  0.21%  10.6  440s\n",
      " 571180 256847  510.09841   29  120  510.63440  509.54667  0.21%  10.6  445s\n",
      " 578260 259747  509.85694   29  127  510.63440  509.54910  0.21%  10.6  450s\n",
      " 586058 262961  509.84123   36  118  510.63440  509.55193  0.21%  10.6  455s\n",
      " 593020 265593  510.44213   36  112  510.63440  509.55424  0.21%  10.6  460s\n",
      " 600564 269031     cutoff   32       510.63440  509.55690  0.21%  10.6  465s\n",
      " 607936 271946  509.91962   26  125  510.63440  509.55912  0.21%  10.6  470s\n",
      " 615359 275013  510.60745   43  105  510.63440  509.56168  0.21%  10.6  475s\n",
      " 623168 277977  510.21104   36  116  510.63440  509.56496  0.21%  10.6  480s\n",
      " 630309 280945     cutoff   49       510.63440  509.56712  0.21%  10.6  485s\n",
      " 638029 283872  510.45184   42  104  510.63440  509.56976  0.21%  10.6  490s\n",
      " 646389 287182     cutoff   43       510.63440  509.57257  0.21%  10.6  495s\n",
      " 653600 290265     cutoff   31       510.63440  509.57464  0.21%  10.6  500s\n",
      " 661460 293413  510.15798   40  110  510.63440  509.57700  0.21%  10.6  505s\n",
      " 667976 296031  510.18460   35  115  510.63440  509.57902  0.21%  10.6  510s\n",
      " 675973 299350  510.22421   39  110  510.63440  509.58149  0.21%  10.6  515s\n",
      " 683829 302642  509.87443   25  132  510.63440  509.58342  0.21%  10.6  520s\n",
      " 691386 305443     cutoff   40       510.63440  509.58586  0.21%  10.6  525s\n",
      " 699123 308383  510.19383   46  100  510.63440  509.58808  0.20%  10.6  530s\n",
      " 706839 311494  510.40193   48   98  510.63440  509.59045  0.20%  10.6  535s\n",
      " 714732 314510  510.40966   46  101  510.63440  509.59307  0.20%  10.6  540s\n",
      " 719351 316292     cutoff   31       510.63440  509.59435  0.20%  10.6  545s\n",
      " 726046 318950  510.33037   58   85  510.63440  509.59642  0.20%  10.6  550s\n",
      " 733386 321891  510.46412   40  102  510.63440  509.59873  0.20%  10.6  555s\n",
      " 741138 324894  509.60176   28  130  510.63440  509.60100  0.20%  10.6  560s\n",
      " 749033 327852  510.25649   39  118  510.63440  509.60293  0.20%  10.6  565s\n",
      " 756708 330659  510.30891   38  109  510.63440  509.60509  0.20%  10.6  570s\n",
      " 764410 333613  509.71339   30  119  510.63440  509.60733  0.20%  10.6  575s\n",
      " 771386 336132  510.15027   38  115  510.63440  509.60942  0.20%  10.6  580s\n",
      " 778102 338638     cutoff   29       510.63440  509.61105  0.20%  10.6  585s\n",
      " 783723 340773     cutoff   39       510.63440  509.61214  0.20%  10.6  590s\n",
      " 788129 342430  509.87782   34  114  510.63440  509.61338  0.20%  10.6  595s\n",
      " 792961 344047  509.61548   29  118  510.63440  509.61483  0.20%  10.6  600s\n",
      " 799782 346556  510.36680   40  110  510.63440  509.61622  0.20%  10.6  605s\n",
      " 804010 348364  509.72067   44  101  510.63440  509.61711  0.20%  10.6  610s\n",
      " 808777 350130     cutoff   42       510.63440  509.61847  0.20%  10.6  615s\n",
      " 814031 352366  510.61237   46  103  510.63440  509.61969  0.20%  10.6  620s\n",
      " 820670 354894  510.40200   48  102  510.63440  509.62138  0.20%  10.6  625s\n",
      " 827484 357601  510.62063   49   99  510.63440  509.62310  0.20%  10.5  630s\n",
      " 834636 360273  510.10363   33  125  510.63440  509.62519  0.20%  10.5  635s\n",
      " 841141 362880  510.18029   38  115  510.63440  509.62670  0.20%  10.5  640s\n",
      " 848965 365951  509.62923   30  119  510.63440  509.62860  0.20%  10.5  645s\n",
      " 856647 368864  510.52683   39  113  510.63440  509.63033  0.20%  10.5  650s\n",
      " 862102 370844  509.98554   36  116  510.63440  509.63171  0.20%  10.5  655s\n",
      " 865913 372318  509.71470   28  124  510.63440  509.63269  0.20%  10.5  660s\n",
      " 870715 373993     cutoff   68       510.63440  509.63382  0.20%  10.5  665s\n",
      " 873850 375207  509.84770   37  117  510.63440  509.63454  0.20%  10.5  670s\n",
      " 876840 376348     cutoff   35       510.63440  509.63536  0.20%  10.5  675s\n",
      " 881688 378097  510.62377   50   90  510.63440  509.63649  0.20%  10.5  680s\n",
      " 887877 380489  509.71152   30  118  510.63440  509.63815  0.20%  10.5  685s\n",
      " 893937 382732  510.38592   43  104  510.63440  509.63963  0.19%  10.5  690s\n",
      " 900648 385182     cutoff   53       510.63440  509.64127  0.19%  10.5  695s\n",
      " 905977 387242  510.59955   48   99  510.63440  509.64223  0.19%  10.5  700s\n",
      " 911267 389157  510.49734   49   93  510.63440  509.64338  0.19%  10.5  705s\n",
      " 917793 391511     cutoff   47       510.63440  509.64490  0.19%  10.5  710s\n",
      " 923331 393529  510.27486   37  116  510.63440  509.64617  0.19%  10.5  715s\n",
      " 926812 394773  509.91636   35  112  510.63440  509.64701  0.19%  10.5  720s\n",
      " 928505 395384  509.81308   36  117  510.63440  509.64742  0.19%  10.5  725s\n",
      " 932835 397069  510.48523   40  110  510.63440  509.64827  0.19%  10.5  730s\n",
      " 936398 398531     cutoff   39       510.63440  509.64909  0.19%  10.5  735s\n",
      " 939340 399715  509.65023   26  131  510.63440  509.64972  0.19%  10.5  740s\n",
      " 944828 402107  509.75482   35  116  510.63440  509.65089  0.19%  10.5  745s\n",
      " 948266 403325  509.88889   25  135  510.63440  509.65165  0.19%  10.5  750s\n",
      " 953788 405294  510.44449   44  109  510.63440  509.65284  0.19%  10.5  755s\n",
      " 958489 407079  510.16966   30  120  510.63440  509.65386  0.19%  10.5  760s\n",
      " 962950 408795  509.80616   32  119  510.63440  509.65490  0.19%  10.5  765s\n",
      " 968556 410706  509.77613   31  124  510.63440  509.65601  0.19%  10.5  770s\n",
      " 974178 412826     cutoff   33       510.63440  509.65723  0.19%  10.5  775s\n",
      " 979024 414467  510.01715   35  115  510.63440  509.65844  0.19%  10.5  780s\n",
      " 984433 416332     cutoff   41       510.63440  509.65952  0.19%  10.5  785s\n",
      " 988650 417976  510.08813   39  112  510.63440  509.66028  0.19%  10.5  790s\n",
      " 994616 420277  509.89789   32  122  510.63440  509.66142  0.19%  10.5  795s\n",
      " 1000569 422494  510.29506   42  107  510.63440  509.66283  0.19%  10.5  800s\n",
      " 1005313 424026  510.46898   38  103  510.63440  509.66398  0.19%  10.5  805s\n",
      " 1011125 426166  509.80061   31  118  510.63440  509.66533  0.19%  10.5  810s\n",
      " 1017792 428759     cutoff   33       510.63440  509.66658  0.19%  10.5  815s\n",
      " 1023867 430993  509.84598   29  122  510.63440  509.66790  0.19%  10.5  820s\n",
      " 1030348 433382     cutoff   40       510.63440  509.66916  0.19%  10.5  825s\n",
      " 1035677 435394     cutoff   44       510.63440  509.67014  0.19%  10.5  830s\n",
      " 1043469 438295     cutoff   40       510.63440  509.67160  0.19%  10.5  835s\n",
      " 1051112 440818     cutoff   59       510.63440  509.67311  0.19%  10.5  840s\n",
      " 1059461 443723  509.91697   27  123  510.63440  509.67468  0.19%  10.5  845s\n",
      " 1066037 446268  509.90508   31  119  510.63440  509.67605  0.19%  10.5  850s\n",
      " 1070886 448007     cutoff   45       510.63440  509.67695  0.19%  10.5  855s\n",
      " 1076078 449965  510.02312   35  116  510.63440  509.67786  0.19%  10.5  860s\n",
      " 1082206 452081     cutoff   47       510.63440  509.67901  0.19%  10.5  865s\n",
      " 1088316 454249  510.09512   31  118  510.63440  509.68037  0.19%  10.5  870s\n",
      " 1094246 456301  510.37271   40  107  510.63440  509.68163  0.19%  10.5  875s\n",
      " 1100315 458542  510.40089   42  107  510.63440  509.68275  0.19%  10.5  880s\n",
      " 1105714 460457  510.56362   40  106  510.63440  509.68380  0.19%  10.5  885s\n",
      " 1111727 462607     cutoff   41       510.63440  509.68501  0.19%  10.5  890s\n",
      " 1117031 464421  509.90394   33  117  510.63440  509.68601  0.19%  10.5  895s\n",
      " 1122980 466265     cutoff   32       510.63440  509.68733  0.19%  10.5  900s\n",
      " 1128624 468548  510.39554   41  104  510.63440  509.68842  0.19%  10.5  905s\n",
      " 1136375 471460     cutoff   38       510.63440  509.68984  0.18%  10.5  910s\n",
      " 1143752 474062  510.53766   50   90  510.63440  509.69116  0.18%  10.5  915s\n",
      " 1152069 477148     cutoff   44       510.63440  509.69280  0.18%  10.5  920s\n",
      " 1159263 479674  510.54843   41  112  510.63440  509.69389  0.18%  10.5  925s\n",
      " 1166340 482209  510.17321   40  105  510.63440  509.69513  0.18%  10.5  930s\n",
      " 1170530 483719  510.38623   39  112  510.63440  509.69586  0.18%  10.5  935s\n",
      " 1175430 485362     cutoff   37       510.63440  509.69674  0.18%  10.5  940s\n",
      " 1180071 487040     cutoff   30       510.63440  509.69748  0.18%  10.5  945s\n",
      " 1184932 488797  509.80605   27  128  510.63440  509.69835  0.18%  10.5  950s\n",
      " 1192602 491749     cutoff   32       510.63440  509.69988  0.18%  10.5  955s\n",
      " 1200277 494423  509.94949   33  117  510.63440  509.70105  0.18%  10.5  960s\n",
      " 1208126 497177  510.33486   37  116  510.63440  509.70252  0.18%  10.5  965s\n",
      " 1215926 499915  510.10132   30  118  510.63440  509.70361  0.18%  10.4  970s\n",
      " 1220076 501339  510.51575   45  104  510.63440  509.70428  0.18%  10.4  975s\n",
      " 1226089 503228     cutoff   50       510.63440  509.70533  0.18%  10.4  980s\n",
      " 1232042 505288  509.86029   28  125  510.63440  509.70641  0.18%  10.4  985s\n",
      " 1239215 507942  509.70775   31  121  510.63440  509.70735  0.18%  10.4  990s\n",
      " 1245094 509971     cutoff   31       510.63440  509.70815  0.18%  10.4  995s\n",
      " 1252863 512659  510.10110   32  120  510.63440  509.70935  0.18%  10.4 1000s\n",
      " 1260576 515200  509.98882   33  115  510.63440  509.71063  0.18%  10.4 1005s\n",
      " 1268276 517993     cutoff   36       510.63440  509.71183  0.18%  10.4 1010s\n",
      " 1276025 520691     cutoff   33       510.63440  509.71299  0.18%  10.4 1015s\n",
      " 1283781 523629     cutoff   36       510.63440  509.71388  0.18%  10.4 1020s\n",
      " 1291710 526454  510.46254   39  112  510.63440  509.71486  0.18%  10.4 1025s\n",
      " 1298697 528957  509.71622   33  114  510.63440  509.71581  0.18%  10.4 1030s\n",
      " 1304098 530782  510.62509   51   92  510.63440  509.71668  0.18%  10.4 1035s\n",
      " 1308922 532414 infeasible   41       510.63440  509.71744  0.18%  10.4 1040s\n",
      " 1316085 535064  510.33564   37  113  510.63440  509.71840  0.18%  10.4 1045s\n",
      " 1323816 537809  509.95698   33  121  510.63440  509.71959  0.18%  10.4 1050s\n",
      " 1332031 540742  510.48720   47  100  510.63440  509.72098  0.18%  10.4 1055s\n",
      " 1339391 543253  510.01335   29  123  510.63440  509.72215  0.18%  10.4 1060s\n",
      " 1347092 545863  509.92368   39  110  510.63440  509.72337  0.18%  10.4 1065s\n",
      " 1355044 548603  509.98308   30  125  510.63440  509.72449  0.18%  10.4 1070s\n",
      " 1362268 551205  510.21426   34  117  510.63440  509.72553  0.18%  10.4 1075s\n",
      " 1369325 553918  510.59947   40  107  510.63440  509.72661  0.18%  10.4 1080s\n",
      " 1377652 556759     cutoff   30       510.63440  509.72784  0.18%  10.4 1085s\n",
      " 1385396 559560  510.52899   45  102  510.63440  509.72906  0.18%  10.4 1090s\n",
      " 1393113 562288  510.25364   41  107  510.63440  509.73024  0.18%  10.4 1095s\n",
      " 1400858 564855  510.53034   37  117  510.63440  509.73145  0.18%  10.4 1100s\n",
      " 1408541 567624  510.41636   41  107  510.63440  509.73251  0.18%  10.4 1105s\n",
      " 1415790 570161  510.38061   39  115  510.63440  509.73367  0.18%  10.4 1110s\n",
      " 1422304 572406  509.93459   34  113  510.63440  509.73462  0.18%  10.4 1115s\n",
      " 1430119 575214  510.62777   36  119  510.63440  509.73568  0.18%  10.4 1120s\n",
      " 1437604 577861  510.35081   44  102  510.63440  509.73678  0.18%  10.4 1125s\n",
      " 1444865 580364  509.95083   31  129  510.63440  509.73788  0.18%  10.4 1130s\n",
      " 1450920 582456  510.60274   44  103  510.63440  509.73867  0.18%  10.4 1135s\n",
      " 1455194 583884  510.01728   36  111  510.63440  509.73930  0.18%  10.4 1140s\n",
      "\n",
      "Explored 1459639 nodes (15183633 simplex iterations) in 1143.33 seconds\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 4: 510.634 510.745 510.775 514.127 \n",
      "\n",
      "Solve interrupted\n",
      "Best objective 5.106344031013e+02, best bound 5.097399774888e+02, gap 0.1752%\n",
      "\n",
      "User-callback calls 2976416, time in user-callback 1.04 sec\n",
      "1165.172298 seconds (107.97 M allocations: 3.285 GiB, 0.10% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(510.6344031013072, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.530197  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.781944])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time obj_value, β_primal = compute_primal(X_train, y_train, k, γ, t_α, σ_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogFile: Dual.txt.\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 102 rows, 201 columns and 601 nonzeros\n",
      "Model fingerprint: 0x6124a2b8\n",
      "Variable types: 1 continuous, 200 integer (200 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [8e-06, 2e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 5e+02]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 102 rows, 201 columns, 601 nonzeros\n",
      "Variable types: 1 continuous, 200 integer (200 binary)\n",
      "\n",
      "Root relaxation: objective 5.034034e+02, 21 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  505.52990    0    2          -  505.52990      -     -    1s\n",
      "     0     2  505.52990    0    2          -  505.52990      -     -    2s\n",
      "   446   553  511.52237   11    2          -  509.54137      -   2.9    7s\n",
      "*  515   567              38     514.6474232  509.54187  0.99%   2.9    8s\n",
      "   698   794  511.90732   35    -  514.64742  509.54262  0.99%   2.8   10s\n",
      "  1018   901  513.75028   36    -  514.64742  509.55648  0.99%   2.9   16s\n",
      "  1114   928  509.87453   18    2  514.64742  509.55648  0.99%   2.9   20s\n",
      "H 1116   882                     511.8312455  509.73493  0.41%   2.9   21s\n",
      "  1117   883  509.96538   40   16  511.83125  509.73493  0.41%   2.9   26s\n",
      "  1349   978     cutoff   38       511.83125  509.97669  0.36%   3.5   30s\n",
      "  1657  1135     cutoff   40       511.83125  510.00003  0.36%   3.5   38s\n",
      "  1781  1179  511.47609   48    -  511.83125  510.01607  0.35%   3.5   41s\n",
      "  2089  1315     cutoff   41       511.83125  510.05108  0.35%   3.5   45s\n",
      "* 2189  1255              68     511.8174685  510.05901  0.34%   3.5   47s\n",
      "* 2369  1168              69     511.3376499  510.06824  0.25%   3.6   51s\n",
      "  2595  1225     cutoff   40       511.33765  510.08437  0.25%   3.6   56s\n",
      "  2879  1333  511.06775   40    2  511.33765  510.09814  0.24%   3.6   64s\n",
      "  3031  1364     cutoff   64       511.33765  510.09938  0.24%   3.5   66s\n",
      "  3139  1406  511.07731   45    -  511.33765  510.10413  0.24%   3.5   70s\n",
      "  3380  1447  511.22185   46    2  511.33765  510.11611  0.24%   3.6   78s\n",
      "  3525  1500  511.33256   66    -  511.33765  510.11810  0.24%   3.6   82s\n",
      "  3674  1568     cutoff   40       511.33765  510.12028  0.24%   3.6   86s\n",
      "* 3718  1411              41     511.2138125  510.12271  0.21%   3.6   87s\n",
      "  3970  1516     cutoff   32       511.21381  510.12594  0.21%   3.6   91s\n",
      "  4274  1685     cutoff   50       511.21381  510.13174  0.21%   3.7   95s\n",
      "* 4442  1489              88     511.0431946  510.13622  0.18%   3.7   99s\n",
      "  4569  1592     cutoff   39       511.04319  510.14324  0.18%   3.7  100s\n",
      "  4882  1779  510.62185   35    5  511.04319  510.15140  0.17%   3.7  105s\n",
      "  5251  1975     cutoff   59       511.04319  510.16348  0.17%   3.7  114s\n",
      "  5408  2071  511.03799   36    2  511.04319  510.17089  0.17%   3.8  116s\n",
      "  5580  2210  510.80494   72    3  511.04319  510.17212  0.17%   3.8  121s\n",
      "* 5749  1982              43     510.9395582  510.17534  0.15%   3.8  125s\n",
      "  6024  2181  510.91554  127    2  510.93956  510.18192  0.15%   3.8  139s\n",
      "  6245  2275  510.92017  128    4  510.93956  510.18514  0.15%   3.7  147s\n",
      "  6401  2350  510.92290  142    4  510.93956  510.18741  0.15%   3.8  153s\n",
      "  6563  2510  510.93388  178    2  510.93956  510.19074  0.15%   3.8  157s\n",
      "  6772  2611  510.87292   58    -  510.93956  510.19524  0.15%   3.8  161s\n",
      "  7230  2943     cutoff   69       510.93956  510.21254  0.14%   3.8  166s\n",
      "  7677  3222     cutoff   75       510.93956  510.22247  0.14%   3.8  172s\n",
      "* 7747  2733              40     510.8777289  510.22247  0.13%   3.8  172s\n",
      "  7943  2739     cutoff   94       510.87773  510.23169  0.13%   3.8  175s\n",
      "  8225  3042     cutoff   40       510.87773  510.23889  0.13%   3.8  180s\n",
      "  8756  3323     cutoff   44       510.87773  510.25224  0.12%   3.9  185s\n",
      "  9290  3629     cutoff   49       510.87773  510.27020  0.12%   3.9  191s\n",
      "  9961  4016     cutoff   96       510.87773  510.27747  0.12%   3.9  198s\n",
      " 10270  4180     cutoff   80       510.87773  510.29036  0.11%   3.9  202s\n",
      "*10434  3222              53     510.7887890  510.29075  0.10%   3.9  205s\n",
      " 11198  3583     cutoff   78       510.78879  510.31407  0.09%   4.1  212s\n",
      " 11544  3734     cutoff   42       510.78879  510.32186  0.09%   4.1  217s\n",
      " 11877  3997     cutoff   51       510.78879  510.33488  0.09%   4.1  220s\n",
      "*12385  2974              35     510.7018401  510.34156  0.07%   4.1  224s\n",
      " 12665  3002     cutoff   96       510.70184  510.34760  0.07%   4.1  225s\n",
      " 13280  3255  510.55317   33    5  510.70184  510.36725  0.07%   4.2  230s\n",
      " 13890  3436     cutoff   54       510.70184  510.38853  0.06%   4.3  235s\n",
      " 14852  3790     cutoff   62       510.70184  510.41061  0.06%   4.5  245s\n",
      " 15632  4119  510.65526  105    4  510.70184  510.42337  0.05%   4.5  251s\n",
      " 15987  4251     cutoff  116       510.70184  510.43109  0.05%   4.6  255s\n",
      " 16671  4441     cutoff   56       510.70184  510.44387  0.05%   4.6  262s\n",
      " 17122  4718     cutoff   89       510.70184  510.44921  0.05%   4.6  269s\n",
      " 17574  4844  510.66908   58    3  510.70184  510.45412  0.05%   4.6  272s\n",
      " 17938  4936     cutoff   71       510.70184  510.45911  0.05%   4.6  275s\n",
      "*18080  4568              38     510.6878020  510.45940  0.04%   4.7  277s\n",
      " 18706  4839  510.63723   45    2  510.68780  510.47306  0.04%   4.7  284s\n",
      " 19013  4968  510.64906   56    4  510.68780  510.47799  0.04%   4.7  287s\n",
      " 19729  5187  510.66984   52    2  510.68780  510.48920  0.04%   4.8  295s\n",
      " 20418  5302     cutoff   85       510.68780  510.49885  0.04%   4.9  300s\n",
      " 20865  5374     cutoff   50       510.68780  510.50889  0.04%   4.9  306s\n",
      " 21525  5594     cutoff  112       510.68780  510.51510  0.03%   5.0  312s\n",
      " 22178  5700     cutoff   50       510.68780  510.52336  0.03%   5.1  317s\n",
      " 22552  5679  510.64237   48    2  510.68780  510.52786  0.03%   5.1  320s\n",
      " 23170  5846  510.67560   58    -  510.68780  510.53641  0.03%   5.2  326s\n",
      " 23917  6034     cutoff   96       510.68780  510.54346  0.03%   5.2  333s\n",
      " 24312  6074     cutoff  114       510.68780  510.54698  0.03%   5.3  335s\n",
      " 25064  6164  510.58943   38    5  510.68780  510.55394  0.03%   5.3  341s\n",
      " 25493  6172     cutoff   74       510.68780  510.55754  0.03%   5.3  351s\n",
      " 25735  6216     cutoff   80       510.68780  510.55754  0.03%   5.4  363s\n",
      " 26193  6269     cutoff  162       510.68780  510.56203  0.02%   5.4  375s\n",
      " 26645  6235     cutoff   36       510.68780  510.56789  0.02%   5.4  380s\n",
      " 27112  6189     cutoff   58       510.68780  510.57279  0.02%   5.5  386s\n",
      " 27892  6068     cutoff   44       510.68780  510.58084  0.02%   5.5  393s\n",
      " 28246  5974     cutoff   60       510.68780  510.58672  0.02%   5.6  395s\n",
      " 28963  5827     cutoff   56       510.68780  510.59408  0.02%   5.7  401s\n",
      "*28991  1897              36     510.6344031  510.59408  0.01%   5.7  401s\n",
      "\n",
      "Cutting planes:\n",
      "  Lazy constraints: 1062\n",
      "\n",
      "Explored 29339 nodes (167894 simplex iterations) in 401.72 seconds\n",
      "Thread count was 4 (of 4 available processors)\n",
      "\n",
      "Solution count 10: 510.634 510.688 510.702 ... 511.817\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.106344030994e+02, best bound 5.105988874976e+02, gap 0.0070%\n",
      "\n",
      "User-callback calls 65359, time in user-callback 362.09 sec\n",
      "401.961189 seconds (79.32 M allocations: 7.413 GiB, 0.51% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(510.6344030993802, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.530197  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.781944])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time obj_value, β_dual = compute_dual(X_train, y_train, k, γ, t_α, σ_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×2 Array{Float64,2}:\n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 1.0  0.530197\n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " ⋮            \n",
       " 0.0  0.0     \n",
       " 1.0  0.49755 \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 1.0  0.781944"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcat(β_true, β_primal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×2 Array{Float64,2}:\n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 1.0  0.530197\n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " ⋮            \n",
       " 0.0  0.0     \n",
       " 1.0  0.497551\n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 0.0  0.0     \n",
       " 1.0  0.781944"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcat(β_true, β_dual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0050648193214879456"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_insample_R2(X_train*β_primal, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005064827479825951"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_insample_R2(X_train*β_dual, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02045648728559335"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_OR2(X_test*β_primal, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02045648572155312"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_OR2(X_test*β_dual, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
